# Docker Compose for AI Foundry SPA Local Development
# This file provides a complete containerized development environment
# Run with: docker-compose up -d

version: '3.8'

services:
  # Azure Storage Emulator
  azurite:
    image: mcr.microsoft.com/azure-storage/azurite:latest
    container_name: ai-foundry-azurite
    ports:
      - "10000:10000"  # Blob service
      - "10001:10001"  # Queue service  
      - "10002:10002"  # Table service
    volumes:
      - azurite-data:/data
    command: "azurite --blobHost 0.0.0.0 --queueHost 0.0.0.0 --tableHost 0.0.0.0 --location /data --debug /data/debug.log"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:10000/devstoreaccount1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s

  # Backend Function App (when containerized)
  # Uncomment and customize when you create a Dockerfile for the Function App
  # backend:
  #   build: 
  #     context: ./src/backend
  #     dockerfile: Dockerfile
  #   container_name: ai-foundry-backend
  #   ports:
  #     - "7071:80"
  #   environment:
  #     - AzureWebJobsStorage=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
  #     - FUNCTIONS_WORKER_RUNTIME=dotnet-isolated
  #     - AI_FOUNDRY_ENDPOINT=${AI_FOUNDRY_ENDPOINT}
  #     - AI_FOUNDRY_DEPLOYMENT=${AI_FOUNDRY_DEPLOYMENT:-gpt-4o-mini}
  #     - AI_FOUNDRY_AGENT_NAME=${AI_FOUNDRY_AGENT_NAME:-AI in A Box}
  #   depends_on:
  #     azurite:
  #       condition: service_healthy
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost/api/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s

  # Frontend Development Server (when containerized)
  # Uncomment and customize when you want to run frontend in container
  # frontend:
  #   build:
  #     context: ./src/frontend
  #     dockerfile: Dockerfile.dev
  #   container_name: ai-foundry-frontend
  #   ports:
  #     - "5173:5173"
  #   volumes:
  #     - ./src/frontend:/app
  #     - /app/node_modules
  #   environment:
  #     - VITE_BACKEND_URL=http://localhost:7071/api
  #     - VITE_USE_BACKEND=true
  #     - VITE_PUBLIC_MODE=true
  #   depends_on:
  #     - backend

volumes:
  azurite-data:
    driver: local

networks:
  default:
    name: ai-foundry-network
    driver: bridge

# Usage Examples:
#
# Start Azurite only (recommended for local development):
#   docker-compose up azurite -d
#
# Start all services:
#   docker-compose up -d
#
# View logs:
#   docker-compose logs -f azurite
#
# Stop services:
#   docker-compose down
#
# Clean up everything:
#   docker-compose down -v
#
# Environment Variables:
# Create a .env file in the project root with:
#   AI_FOUNDRY_ENDPOINT=https://your-ai-foundry.cognitiveservices.azure.com/
#   AI_FOUNDRY_DEPLOYMENT=gpt-4o-mini
#   AI_FOUNDRY_AGENT_NAME=AI in A Box